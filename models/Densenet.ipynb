{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67aa54-1c7b-4aa6-9866-b0f3f0553707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import glob\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.tensorboard import summary as summary_lib\n",
    "from PIL import Image  # Add this import\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4097e3-c728-45d7-bff0-0800322f9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f358aa3-487a-4b2f-aced-2f2cbdf78112",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((227, 227)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1c317-9c12-4c6c-8ee5-d63cfdb66a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe6d04-06af-46cb-9ebd-4417dbd3c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sigma = 0\n",
    "max_sigma = 50/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7906c-cd8d-473d-a4bc-17b0bc857233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(image, sigma):\n",
    "    noise = torch.randn_like(image) * sigma\n",
    "    noisy_image = torch.clamp(image + noise, 0, 1)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fca37b-b513-4659-8f94-1c44a667a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_noisy_image(img, name):\n",
    "    img = img.view(img.size(0), 3, 227, 227)\n",
    "    torchvision.utils.save_image(img, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa487c6-1e4a-47a0-9f23-437d797e387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_folder, sigma_values, transform=None, device=torch.device(\"cpu\")):\n",
    "        self.image_paths = glob.glob(os.path.join(image_folder, \"*.png\"))  # Adjust this for your image format\n",
    "        self.sigma_values = sigma_values\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sigma_values)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)  # Convert NumPy array to PIL Image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sigma = torch.tensor(self.sigma_values[index], dtype=torch.float32, device=self.device)  # Ensure sigma is float32\n",
    "        return image.to(self.device), sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0777fc8-af37-4366-a6fa-6de0dd41715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customFunction():\n",
    "    sigma_values = []\n",
    "    i = 1\n",
    "    j = 1\n",
    "    for inputs, _ in train_loader:\n",
    "        sigma = np.random.uniform(min_sigma, max_sigma)\n",
    "        sigma_values.append(sigma)\n",
    "        noisy_inputs = add_noise(inputs, sigma)\n",
    "        noisy_image = (noisy_inputs.squeeze().numpy() * 255).astype(np.uint8)\n",
    "        if i <= 100:\n",
    "            new_image = torch.cat((inputs, noisy_inputs), 0)\n",
    "            save_noisy_image(new_image, f\"C:/Users/IICT3/Bithi/Noise regression/Output100/{j}.png\")\n",
    "        i += 1\n",
    "        save_noisy_image(noisy_inputs, f\"C:/Users/IICT3/Bithi/Noise regression/Noisy image/{j}.png\")\n",
    "        j += 1\n",
    "    sigma_values = np.array(sigma_values)\n",
    "    return sigma_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdaf1f-7aaf-42dd-8f49-b1397b4bcc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_values = customFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01821495-6f52-40d2-a837-be0797ea5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"C:/Users/IICT3/Bithi/Noise regression/Noisy image\"\n",
    "dataset = CustomDataset(image_folder=input_dir, sigma_values=sigma_values, transform=transform, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2385a-bb0f-4225-a90c-e55a8638d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2197b4-e7b8-4d15-bb2e-aaad8289e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epoch, writer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    for batch_idx, (inputs, targets_batch) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device).float()  # Convert inputs to float32\n",
    "        targets_batch = targets_batch.unsqueeze(1).to(device).float()  # Convert targets to float32\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predictions.extend(outputs.cpu().detach().numpy())\n",
    "        targets.extend(targets_batch.cpu().detach().numpy())\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(inputs)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Train Epoch: {epoch}\\tAverage Loss: {avg_loss:.6f}')\n",
    "    mae, rmse, r2 = calculate_metrics(predictions, targets)\n",
    "    print(f'MAE: {mae:.6f}, RMSE: {rmse:.6f}, R2 Score: {r2:.6f}')\n",
    "    writer.add_scalar('Training Loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Training MAE', mae, epoch)\n",
    "    writer.add_scalar('Training RMSE', rmse, epoch)\n",
    "    writer.add_scalar('Training R2 Score', r2, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ffe3b-0c58-4fad-958b-7010f2debeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, epoch, writer):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets_batch in test_loader:\n",
    "            inputs = inputs.to(device).float()  # Convert inputs to float32\n",
    "            targets_batch = targets_batch.unsqueeze(1).to(device).float()  # Convert targets to float32\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, targets_batch).item()\n",
    "\n",
    "            predictions.extend(outputs.cpu().detach().numpy())\n",
    "            targets.extend(targets_batch.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    print(f'Test Epoch: {epoch}\\tAverage Loss: {avg_loss:.6f}')\n",
    "    mae, rmse, r2 = calculate_metrics(predictions, targets)\n",
    "    print(f'MAE: {mae:.6f}, RMSE: {rmse:.6f}, R2 Score: {r2:.6f}')\n",
    "    writer.add_scalar('Testing Loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Testing MAE', mae, epoch)\n",
    "    writer.add_scalar('Testing RMSE', rmse, epoch)\n",
    "    writer.add_scalar('Testing R2 Score', r2, epoch)\n",
    "    #plot_predictions(predictions, targets, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d7c9a-775c-4c60-8211-8c3f84751e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, targets):\n",
    "    predictions = np.array(predictions).reshape(-1)\n",
    "    targets = np.array(targets).reshape(-1)\n",
    "    mae = mean_absolute_error(targets, predictions)\n",
    "    rmse = mean_squared_error(targets, predictions, squared=False)\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235465f-5114-4b44-9785-431fd260ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(predictions, targets, epoch):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(targets, predictions, alpha=0.5)\n",
    "    plt.xlabel('Ground Truth')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title(f'Predictions vs. Ground Truth (Epoch {epoch})')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'predictions_vs_ground_truth_epoch_{epoch}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3d434-882f-40d0-81f9-b92ee6a8259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996df60-8ef2-461e-b1be-4b9bc90594e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The parameter 'pretrained' is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Arguments other than a weight enum or `None` for 'weights' are deprecated\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b1b4e-08fc-4023-8b37-acbb429369fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Densenet\n",
    "class NoiseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NoiseNet, self).__init__()\n",
    "        self.model = models.densenet121(pretrained=True)\n",
    "        self.model.classifier = nn.Sequential(nn.Linear(1024, 512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.25),\n",
    "                                  nn.Linear(512,256),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.5),\n",
    "                                  nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = NoiseNet().to(device)\n",
    "#summary(model1,(3,227,227))\n",
    "#model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7108c8a-0b3a-475a-ba71-6faca1c6d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Densenet\n",
    "\n",
    "from tensorboard.backend.event_processing.event_file_loader import EventFileLoader\n",
    "\n",
    "# Initialize empty lists to store metrics\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "\n",
    "# Training and testing loop with cross-validation\n",
    "epochs = 30\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    test_subset = torch.utils.data.Subset(dataset, test_idx)\n",
    "\n",
    "    trainloader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "    testloader = DataLoader(test_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = NoiseNet().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    custom_run_name = f\"Dense_fold_{fold + 1}\"\n",
    "    writer = SummaryWriter(log_dir=f\"runs/{custom_run_name}\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, trainloader, loss_fn, optimizer, epoch, writer)\n",
    "        test(model, testloader, loss_fn, epoch, writer)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # Read scalar values from tensorboard event files\n",
    "\n",
    "    event_file = glob.glob(f\"runs/{custom_run_name}/events.out.tfevents.*\")[0]\n",
    "    event_loader = EventFileLoader(event_file)\n",
    "    scalar_events = [event for event in event_loader.Load()]\n",
    "\n",
    "\n",
    "    # Extract the required scalar values\n",
    "    train_loss = next((event.summary.value[0].simple_value for event in scalar_events if event.step == 1), None)\n",
    "    test_loss = next((event.summary.value[0].simple_value for event in scalar_events if event.step == 2), None)\n",
    "    mae = next((event.summary.value[0].simple_value for event in scalar_events if event.step == 3), None)\n",
    "    rmse = next((event.summary.value[0].simple_value for event in scalar_events if event.step == 4), None)\n",
    "    r2 = next((event.summary.value[0].simple_value for event in scalar_events if event.step == 5), None)\n",
    "\n",
    "\n",
    "    # Append the metrics to the respective lists\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "    r2_list.append(r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3567f7-9449-4490-ad6a-01f2eabb8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3dc068-7024-4b79-9b9a-d5fe08cd3711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kill: 54440: No such process\n"
     ]
    }
   ],
   "source": [
    "!kill 54440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c0ae483-9a36-4df7-8fdc-51f24aa15866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7713034f-08bc-4fd4-af41-f21bb4cdca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 54440), started 2:02:25 ago. (Use '!kill 54440' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f662d5b6375fc3df\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f662d5b6375fc3df\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "logs_base_dir = \"./runs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c83fbc5-52a9-4462-952d-3d17e5b596f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-82719118a22f4db5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-82719118a22f4db5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {logs_base_dir}  --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836598d5-82a6-4a27-8390-00174d519295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
